{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5457b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d90bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = np.load('results/metrics_results_0.npy')\n",
    "data1 = np.load('results/metrics_results_1.npy')\n",
    "data2 = np.load('results/metrics_results_2.npy')\n",
    "data3 = np.load('results/metrics_results_3.npy')\n",
    "data4 = np.load('results/metrics_results_4.npy')\n",
    "data5 = np.load('results/metrics_results_5.npy')\n",
    "data6 = np.load('results/metrics_results_6.npy')\n",
    "data7 = np.load('results/metrics_results_7.npy')\n",
    "data8 = np.load('results/metrics_results_8.npy')\n",
    "data9 = np.load('results/metrics_results_9.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ea57a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.zeros_like(data9)\n",
    "\n",
    "new_data[0] = data0[0]\n",
    "new_data[1] = data1[1]\n",
    "new_data[2] = data2[2]\n",
    "new_data[3] = data3[3]\n",
    "new_data[4] = data4[4]\n",
    "new_data[5] = data5[5]\n",
    "new_data[6] = data6[6]\n",
    "new_data[7] = data8[8]\n",
    "new_data[8] = data7[7]\n",
    "new_data[9] = data9[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d0c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = new_data  # shape: [n_models, n_runs, n_checkpoints, n_metrics]\n",
    "\n",
    "orig_model_names = [\n",
    "    \"OT-CFM\",\n",
    "    \"ICFM\",\n",
    "    \"ICFM-Rej\",\n",
    "    \"OTCFM-Iter20\",\n",
    "    \"OTCFM-Iter200\",\n",
    "    \"OTCFM-Iter10000\",\n",
    "    \"OTCFM-Dir\",\n",
    "    \"OTCFM-Dir-Tight\",\n",
    "    \"OTCFM-Dir-PerfectPairing\",\n",
    "    \"OTCFM-Iter6000\",\n",
    "]\n",
    "\n",
    "orig_metrics_names = [\n",
    "    \"Avg Min Dist\",\n",
    "    \"% Samples > 1.0\",\n",
    "    \"Wasserstein Distance\",\n",
    "    \"Coverage\",\n",
    "    \"MMD\",\n",
    "    \"MDD\",\n",
    "    \"Normalized Wasserstein\",\n",
    "]\n",
    "\n",
    "# Reorder models and rename for clarity\n",
    "model_name_map = {\n",
    "    \"ICFM\": \"I-CFM\",\n",
    "    \"OT-CFM\": \"OT-CFM\",\n",
    "    \"ICFM-Rej\": \"I-CFM-Pruned\",\n",
    "    \"OTCFM-Iter200\": \"Flow Model 200-iter\",\n",
    "    \"OTCFM-Iter6000\": \"Flow Model 6k-iter\",\n",
    "    \"OTCFM-Iter10000\": \"Flow Model 10k-iter\",\n",
    "    \"OTCFM-Dir-PerfectPairing\": \"Directional Align (Normal) Perfect OT\",\n",
    "    \"OTCFM-Dir\": \"Directional Align (Normal) OT-CFM\",\n",
    "    \"OTCFM-Dir-Tight\": \"Directional Align (Tight) OT-CFM\",\n",
    "}\n",
    "\n",
    "desired_model_order = [\n",
    "    \"ICFM\",\n",
    "    \"OT-CFM\",\n",
    "    \"ICFM-Rej\",\n",
    "    \"OTCFM-Iter200\",\n",
    "    \"OTCFM-Iter6000\",\n",
    "    \"OTCFM-Iter10000\",\n",
    "    \"OTCFM-Dir-PerfectPairing\",\n",
    "    \"OTCFM-Dir\",\n",
    "    \"OTCFM-Dir-Tight\",\n",
    "]\n",
    "\n",
    "model_indices = [orig_model_names.index(m) for m in desired_model_order]\n",
    "model_names = [model_name_map[m] for m in desired_model_order]\n",
    "results = results[model_indices, :, :, :]  # Reorder results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1d97c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and rename metrics for clarity\n",
    "metric_name_map = {\n",
    "    \"Avg Min Dist\": \"AMD ↓\",\n",
    "    \"% Samples > 1.0\": \"Failure Rate ↓\",\n",
    "    \"MDD\": \"MDD ↓\",\n",
    "    \"Normalized Wasserstein\": \"Norm. Wassersterin ↓\",\n",
    "}\n",
    "\n",
    "desired_metrics_order = [\n",
    "    \"Avg Min Dist\",\n",
    "    \"% Samples > 1.0\",\n",
    "    \"MDD\",\n",
    "    \"Normalized Wasserstein\",\n",
    "]\n",
    "\n",
    "metric_indices = [orig_metrics_names.index(m) for m in desired_metrics_order]\n",
    "metrics_names = [metric_name_map[m] for m in desired_metrics_order]\n",
    "results = results[:, :, :, metric_indices]  # Reorder results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cda3598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Min per Run → Avg ± Std (Selected Metrics) ===\n",
      "                                                 AMD ↓   Failure Rate ↓            MDD ↓ Norm. Wassersterin ↓\n",
      "I-CFM                                  0.2271 ± 0.0371  2.4512 ± 1.0219  0.0908 ± 0.0297      1.4567 ± 0.1107\n",
      "OT-CFM                                 0.3055 ± 0.0653  5.1367 ± 1.5010  0.0601 ± 0.0230      1.5237 ± 0.2779\n",
      "I-CFM-Pruned                           0.1858 ± 0.0220  1.7188 ± 0.8414  0.1048 ± 0.0390      1.3587 ± 0.1183\n",
      "Flow Model 200-iter                    0.3106 ± 0.0438  4.6094 ± 1.1201  0.0272 ± 0.0104      1.3393 ± 0.2184\n",
      "Flow Model 6k-iter                     0.3250 ± 0.0567  6.0547 ± 1.2437  0.0166 ± 0.0051      1.3963 ± 0.1872\n",
      "Flow Model 10k-iter                    0.3357 ± 0.0348  6.6602 ± 1.9210  0.0301 ± 0.0163      1.4654 ± 0.1675\n",
      "Directional Align (Normal) Perfect OT  0.1540 ± 0.0071  0.7715 ± 0.2370  0.0012 ± 0.0006      0.5109 ± 0.0643\n",
      "Directional Align (Normal) OT-CFM      0.2133 ± 0.0409  2.5000 ± 0.9699  0.0176 ± 0.0059      1.0901 ± 0.1336\n",
      "Directional Align (Tight) OT-CFM       0.2502 ± 0.0305  3.5645 ± 0.6839  0.0159 ± 0.0055      1.1256 ± 0.0688\n"
     ]
    }
   ],
   "source": [
    "n_models = len(model_names)\n",
    "n_metrics = len(metrics_names)\n",
    "\n",
    "min_table = []\n",
    "for model_idx in range(n_models):\n",
    "    row = []\n",
    "    for metric_idx in range(n_metrics):\n",
    "        # min over checkpoints per run: shape [n_runs, n_checkpoints] -> [n_runs]\n",
    "        extrema_per_run = results[model_idx, :, :, metric_idx].min(axis=1)\n",
    "        mean = np.mean(extrema_per_run)\n",
    "        std = np.std(extrema_per_run)\n",
    "        row.append(f\"{mean:.4f} ± {std:.4f}\")\n",
    "    min_table.append(row)\n",
    "\n",
    "df_min = pd.DataFrame(min_table, columns=metrics_names, index=model_names)\n",
    "print(\"\\n=== Min per Run → Avg ± Std (Selected Metrics) ===\")\n",
    "print(df_min.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "source",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
